{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras \n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "train_dir = 'imgs/train'\n",
    "test_dir = 'imgs/test'\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "num_classes = 10\n",
    "img_size = 128\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(img_label):\n",
    "    label = int(list(img_label)[1])\n",
    "    #print(label)\n",
    "    l = [0]*10\n",
    "    l[label]=1\n",
    "    return l\n",
    "\n",
    "def create_train_data():\n",
    "    training_data=[]\n",
    "    for d in os.listdir(train_dir):\n",
    "        l = d\n",
    "        d = os.path.join(train_dir,d)\n",
    "        for img in os.listdir(d):\n",
    "            label = label_img(l)\n",
    "            img_path = os.path.join(d,img)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img,(img_size,img_size))\n",
    "            training_data.append([np.array(img),np.array(label)])\n",
    "    shuffle(training_data)\n",
    "    np.save(\"training_data.npy\",training_data)\n",
    "    return training_data\n",
    "\n",
    "def create_testing_data():\n",
    "    testing_data=[]\n",
    "    for img in os.listdir(test_dir):\n",
    "        img_path = os.path.join(test_dir,img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img,(img_size,img_size))\n",
    "        testing_data.append([np.array(img)])\n",
    "    shuffle(testing_data)\n",
    "    np.save(\"testing_data.npy\",testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"training_data.npy\"):\n",
    "    train_data = np.load(\"training_data.npy\")\n",
    "else:\n",
    "    train_data = create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_data[0][0]\n",
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22424"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data[:-500]\n",
    "test = train_data[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train]).reshape(-1,img_size,img_size,1)\n",
    "y = np.array([i[1] for i in train])\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,img_size,img_size,1)\n",
    "test_y = np.array([i[1] for i in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding = 'same',activation = 'relu',input_shape=(img_size,img_size,1),bias_initializer=keras.initializers.Ones()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
    "\n",
    "model.add(Conv2D(64,kernel_size=(3,3),padding = 'same',activation = 'relu',bias_initializer=keras.initializers.Ones()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
    "\n",
    "model.add(Conv2D(128,kernel_size=(3,3), padding='same', activation='relu',bias_initializer=keras.initializers.Ones()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', bias_initializer=keras.initializers.Ones()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = keras.optimizers.SGD(lr=lr), loss = keras.losses.categorical_crossentropy, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 128, 128, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 4,289,802\n",
      "Trainable params: 4,289,098\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21924 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "21924/21924 [==============================] - 1031s 47ms/step - loss: 0.7815 - acc: 0.7857 - val_loss: 0.2910 - val_acc: 0.9460\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94600, saving model to check01\n",
      "Epoch 2/10\n",
      "21924/21924 [==============================] - 1134s 52ms/step - loss: 0.1781 - acc: 0.9760 - val_loss: 0.1478 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94600 to 0.98000, saving model to check01\n",
      "Epoch 3/10\n",
      "21924/21924 [==============================] - 1113s 51ms/step - loss: 0.1011 - acc: 0.9898 - val_loss: 0.1005 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.98000 to 0.98400, saving model to check01\n",
      "Epoch 4/10\n",
      "21924/21924 [==============================] - 1151s 53ms/step - loss: 0.0694 - acc: 0.9949 - val_loss: 0.0773 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.98400 to 0.98600, saving model to check01\n",
      "Epoch 5/10\n",
      "21924/21924 [==============================] - 1004s 46ms/step - loss: 0.0524 - acc: 0.9968 - val_loss: 0.0670 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.98600 to 0.99400, saving model to check01\n",
      "Epoch 6/10\n",
      "21924/21924 [==============================] - 996s 45ms/step - loss: 0.0418 - acc: 0.9982 - val_loss: 0.0592 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99400\n",
      "Epoch 7/10\n",
      "21924/21924 [==============================] - 997s 45ms/step - loss: 0.0349 - acc: 0.9990 - val_loss: 0.0550 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99400\n",
      "Epoch 8/10\n",
      "21924/21924 [==============================] - 995s 45ms/step - loss: 0.0299 - acc: 0.9993 - val_loss: 0.0519 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99400\n",
      "Epoch 9/10\n",
      "21924/21924 [==============================] - 991s 45ms/step - loss: 0.0264 - acc: 0.9994 - val_loss: 0.0476 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99400\n",
      "Epoch 10/10\n",
      "21924/21924 [==============================] - 990s 45ms/step - loss: 0.0228 - acc: 0.9997 - val_loss: 0.0437 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99400\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('check01', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "driver_train_model = model.fit(X,y,batch_size=batch_size, epochs=epochs,verbose = 1, validation_data=(test_x,test_y), callbacks= callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
